{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# example of one hot encoding for a neural network\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# import tensor as tf\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# example of one hot encoding for a neural network\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Scaling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print('Packages imported...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "# load the train dataset\n",
    "def load_dataset(train, test, evaluation):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tprint(\"load the dataset as a pandas DataFrame\")\n",
    "\ttrain = pd.read_csv(train)\n",
    "\ttest = pd.read_csv(test)\n",
    "\tevaluation = pd.read_csv(evaluation)\n",
    "\n",
    "\ttrain = train.replace(np.nan, 'no_data').astype(str)\n",
    "\ttest = test.replace(np.nan, 'no_data').astype(str)\n",
    "\tevaluation = evaluation.replace(np.nan, 'no_data').astype(str)\n",
    "\n",
    "\tprint(train.info())\n",
    "\n",
    "    # select columns\n",
    "\tprint(\"select columns\")\n",
    "\ttrain_df = train[['consumed_part_name','pfmea_potential_effect_of_failure','pfmea_severity']]\n",
    "\tprint(train_df)\n",
    "\t# train_df['consumed_part_name'] = train_df['consumed_part_name'].fillna('0')\n",
    "\t# train_df['pfmea_potential_effect_of_failure'] = train_df['pfmea_potential_effect_of_failure'].fillna('0')\n",
    "\t# train_df['pfmea_severity'] = train_df['pfmea_severity'].fillna(\"0\")\n",
    "\ttest_df = test[['consumed_part_name','pfmea_potential_effect_of_failure','pfmea_severity']]\n",
    "\tprint(test_df)\n",
    "\t# test_df['consumed_part_name'] = test_df['consumed_part_name'].fillna('0')\n",
    "\t# test_df['pfmea_potential_effect_of_failure'] = test_df['pfmea_potential_effect_of_failure'].fillna('0')\n",
    "\t# test_df['pfmea_severity'] = test_df['pfmea_severity'].fillna(\"0\")\n",
    "\tevaluation_df = evaluation[['consumed_part_name','pfmea_potential_effect_of_failure','pfmea_severity']]\n",
    "\tprint(evaluation_df)\n",
    "\t# evaluation_df['consumed_part_name'] = evaluation_df['consumed_part_name'].fillna('0')\n",
    "\t# evaluation_df['pfmea_potential_effect_of_failure'] = evaluation_df['pfmea_potential_effect_of_failure'].fillna('0')\n",
    "\t# evaluation_df['pfmea_severity'] = evaluation_df['pfmea_severity'].fillna(\"0\")\n",
    "\n",
    "\n",
    "\t# retrieve numpy array\n",
    "\tprint(\"retrieve numpy array\")\n",
    "\t#Considering y variable holds numpy array\n",
    "\t# dataset_train = tf.convert_to_tensor(train_df, dtype=tf.int64)\n",
    "\t# dataset_test = tf.convert_to_tensor(test_df, dtype=tf.int64)\n",
    "\t# evaluation_test = tf.convert_to_tensor(evaluation_df, dtype=tf.int64)\n",
    "\tdataset_train = train_df\n",
    "\tdataset_test = test_df\n",
    "\tevaluation_test = evaluation_df\n",
    "\t# dataset_train = train_df.values\n",
    "\t# dataset_test = test_df.values\n",
    "\t# evaluation_test = evaluation_df.values\n",
    "\n",
    "\t# Define Features and Label\n",
    "\tfeature = ['consumed_part_name','pfmea_potential_effect_of_failure']\n",
    "\tlabel = ['pfmea_severity']\n",
    "\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tprint(\"split into input (X) and output (y) variables\")\n",
    "\tX_train = dataset_train[feature].values\n",
    "\ty_train = dataset_train[label].values\n",
    "\n",
    "\tX_test = dataset_test[feature].values\n",
    "\ty_test = dataset_test[label].values\n",
    "\n",
    "\tX_evaluation = evaluation_test[feature].values\n",
    "\ty_evaluation = evaluation_test[label].values\n",
    "\n",
    "\n",
    "\t# # format all fields as string\n",
    "\t# print(\"format all fields as string\")\n",
    "\t# X_train = X_train.astype(str)\n",
    "\t# X_test = X_test.astype(str)\n",
    "\t# X_evaluation = X_evaluation.astype(str)\n",
    "\t# y_train = y_train.astype(str)\n",
    "\t# y_test = y_test.astype(str)\n",
    "\t# y_evaluation = y_evaluation.astype(str)\n",
    "\n",
    "\t# reshape target to be a 2d array\n",
    "\tprint(\"reshape target to be a 2d array\")\n",
    "\ty_train = y_train.reshape((len(y_train), 1))\n",
    "\ty_test = y_test.reshape((len(y_test), 1))\n",
    "\ty_evaluation = y_evaluation.reshape((len(y_evaluation), 1))\n",
    "\n",
    "\tprint(\"Done\")\n",
    "\n",
    "\n",
    "\treturn X_train, y_train, X_test, y_test, X_evaluation, y_evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [],
   "source": [
    "# prepare input train data\n",
    "def prepare_inputs(X_train, X_test, X_evaluation):\n",
    "\tprint(\"prepare input train data\")\n",
    "\tohe = OrdinalEncoder()\n",
    "\tohe.fit(X_train)\n",
    "\tX_train_enc = ohe.fit_transform(X_train)\n",
    "\tX_test_enc = ohe.fit_transform(X_test)\n",
    "\tX_evaluation_enc = ohe.fit_transform(X_evaluation)\n",
    "\tprint(\"Done\")\n",
    "\treturn X_train_enc, X_test_enc, X_evaluation_enc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [],
   "source": [
    "# prepare target\n",
    "def prepare_targets(y_train, y_test, y_evaluation):\n",
    "\tprint(\"prepare target\")\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\ty_evaluation_enc = le.transform(y_evaluation)\n",
    "\tprint(\"Done\")\n",
    "\treturn y_train_enc, y_test_enc, y_evaluation_enc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "train = 'training.csv'\n",
    "test = 'test.csv'\n",
    "evaluation = 'evaluation.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the dataset as a pandas DataFrame\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 222911 entries, 0 to 222910\n",
      "Data columns (total 30 columns):\n",
      " #   Column                               Non-Null Count   Dtype \n",
      "---  ------                               --------------   ----- \n",
      " 0   plant                                222911 non-null  object\n",
      " 1   line_mrn                             222911 non-null  object\n",
      " 2   sub_process_station                  222911 non-null  object\n",
      " 3   task_number                          222911 non-null  object\n",
      " 4   consumed_part_number                 222911 non-null  object\n",
      " 5   task_list_description                222911 non-null  object\n",
      " 6   consumed_part_top_number             222911 non-null  object\n",
      " 7   consumed_part_name                   222911 non-null  object\n",
      " 8   consumed_part_state                  222911 non-null  object\n",
      " 9   consumed_part_description            222911 non-null  object\n",
      " 10  consumed_part_assembly_instructions  222911 non-null  object\n",
      " 11  consumed_part_top_name               222911 non-null  object\n",
      " 12  task_description                     222911 non-null  object\n",
      " 13  station_number                       222911 non-null  object\n",
      " 14  pfmea_number                         222911 non-null  object\n",
      " 15  pfmea_version                        222911 non-null  object\n",
      " 16  pfmea_local_ecn_number               222911 non-null  object\n",
      " 17  pfmea_local_ecn_effectivity          222911 non-null  object\n",
      " 18  pfmea_maap_failure_mode_group        222911 non-null  object\n",
      " 19  pfmea_maap_risk_level                222911 non-null  object\n",
      " 20  pfmea_potential_failure_mode         222911 non-null  object\n",
      " 21  pfmea_potential_effect_of_failure    222911 non-null  object\n",
      " 22  pfmea_potential_cause_of_failure     222911 non-null  object\n",
      " 23  pfmea_process_control_prevention     222911 non-null  object\n",
      " 24  pfmea_process_control_detection      222911 non-null  object\n",
      " 25  pfmea_severity                       222911 non-null  object\n",
      " 26  pfmea_occurrences                    222911 non-null  object\n",
      " 27  pfmea_detection                      222911 non-null  object\n",
      " 28  pfmea_rpn                            222911 non-null  object\n",
      " 29  uuid                                 222911 non-null  object\n",
      "dtypes: object(30)\n",
      "memory usage: 51.0+ MB\n",
      "None\n",
      "select columns\n",
      "       consumed_part_name           pfmea_potential_effect_of_failure  \\\n",
      "0                   STRAP  Inability to perform next task / operation   \n",
      "1                   STRAP  Inability to perform next task / operation   \n",
      "2               Converter                     Damaged / contamination   \n",
      "3               Converter                                 Safety risk   \n",
      "4               Converter                     Damaged / contamination   \n",
      "...                   ...                                         ...   \n",
      "222906             WASHER                                       Noise   \n",
      "222907           RETAINER                                       Noise   \n",
      "222908             WASHER                  Premature failure of parts   \n",
      "222909             WASHER                                       Noise   \n",
      "222910           RETAINER                  Premature failure of parts   \n",
      "\n",
      "       pfmea_severity  \n",
      "0                 6.0  \n",
      "1                 6.0  \n",
      "2                 7.0  \n",
      "3                 9.0  \n",
      "4                 7.0  \n",
      "...               ...  \n",
      "222906            5.0  \n",
      "222907            5.0  \n",
      "222908            5.0  \n",
      "222909            5.0  \n",
      "222910            5.0  \n",
      "\n",
      "[222911 rows x 3 columns]\n",
      "      consumed_part_name           pfmea_potential_effect_of_failure  \\\n",
      "0           Exhaust Pipe                  Premature failure of parts   \n",
      "1                 Gasket                  Premature failure of parts   \n",
      "2                 WASHER                                       Noise   \n",
      "3                Bracket                                   Vibration   \n",
      "4                Support  Inability to perform next task / operation   \n",
      "...                  ...                                         ...   \n",
      "31840      Control Valve                                     no_data   \n",
      "31841      Control Valve                                     no_data   \n",
      "31842           RETAINER                                       Noise   \n",
      "31843           RETAINER                                       Noise   \n",
      "31844          Cap Screw                  Premature failure of parts   \n",
      "\n",
      "      pfmea_severity  \n",
      "0            no_data  \n",
      "1            no_data  \n",
      "2            no_data  \n",
      "3            no_data  \n",
      "4            no_data  \n",
      "...              ...  \n",
      "31840        no_data  \n",
      "31841        no_data  \n",
      "31842        no_data  \n",
      "31843        no_data  \n",
      "31844        no_data  \n",
      "\n",
      "[31845 rows x 3 columns]\n",
      "      consumed_part_name                  pfmea_potential_effect_of_failure  \\\n",
      "0                SUPPORT                                            no_data   \n",
      "1                  Clamp                         Premature failure of parts   \n",
      "2                 Gasket  Loss of pressure fluid / leakage in fluid syst...   \n",
      "3                 Gasket                         Premature failure of parts   \n",
      "4                  Clamp  Loss of pressure fluid / leakage in fluid syst...   \n",
      "...                  ...                                                ...   \n",
      "63684            CONDUIT                         Premature failure of parts   \n",
      "63685      Control Valve                                            no_data   \n",
      "63686      Control Valve                                            no_data   \n",
      "63687           RETAINER                         Premature failure of parts   \n",
      "63688          Cap Screw                                              Noise   \n",
      "\n",
      "      pfmea_severity  \n",
      "0            no_data  \n",
      "1                7.0  \n",
      "2                7.0  \n",
      "3                7.0  \n",
      "4                7.0  \n",
      "...              ...  \n",
      "63684            4.0  \n",
      "63685        no_data  \n",
      "63686        no_data  \n",
      "63687            5.0  \n",
      "63688            5.0  \n",
      "\n",
      "[63689 rows x 3 columns]\n",
      "retrieve numpy array\n",
      "split into input (X) and output (y) variables\n",
      "reshape target to be a 2d array\n",
      "Done\n",
      "prepare input train data\n",
      "Done\n",
      "prepare target\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ananya_pramanik/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ananya_pramanik/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "X_train, y_train, X_test, y_test, X_evaluation, y_evaluation = load_dataset(train, test, evaluation)\n",
    "\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc,X_evaluation_enc = prepare_inputs(X_train, X_test, X_evaluation)\n",
    "\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc, y_evaluation_enc = prepare_targets(y_train, y_test, y_evaluation)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (222911, 2)\n",
      "y_train (222911, 1)\n",
      "X_test (31845, 2)\n",
      "y_test (31845, 1)\n",
      "X_evaluation (63689, 2)\n",
      "y_evaluation (63689, 1)\n",
      "X_train_enc (222911, 2)\n",
      "X_test_enc (31845, 2)\n",
      "X_evaluation_enc (63689, 2)\n",
      "y_train_enc (222911,)\n",
      "y_test_enc (31845,)\n",
      "y_evaluation_enc (63689,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train',X_train.shape)\n",
    "print('y_train',y_train.shape)\n",
    "print('X_test',X_test.shape)\n",
    "print('y_test',y_test.shape)\n",
    "print('X_evaluation',X_evaluation.shape)\n",
    "print('y_evaluation',y_evaluation.shape)\n",
    "\n",
    "print('X_train_enc',X_train_enc.shape)\n",
    "print('X_test_enc',X_test_enc.shape)\n",
    "print('X_evaluation_enc',X_evaluation_enc.shape)\n",
    "\n",
    "print('y_train_enc',y_train_enc.shape)\n",
    "print('y_test_enc',y_test_enc.shape)\n",
    "print('y_evaluation_enc',y_evaluation_enc.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the  model\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=X_train_enc.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "# summarize layers\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[726.,   7.],\n       [726.,   7.],\n       [191.,   2.],\n       ...,\n       [890.,  21.],\n       [890.,  18.],\n       [626.,  21.]])"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "data": {
      "text/plain": "array([6, 6, 7, ..., 5, 5, 5])"
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_enc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3135/3135 [==============================] - 10s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0013 - val_loss: 0.0000e+00 - val_accuracy: 1.7944e-04\n",
      "Epoch 2/10\n",
      "3135/3135 [==============================] - 7s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0013 - val_loss: 0.0000e+00 - val_accuracy: 1.7944e-04\n",
      "Epoch 3/10\n",
      "3135/3135 [==============================] - 5s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0013 - val_loss: 0.0000e+00 - val_accuracy: 1.7944e-04\n",
      "Epoch 4/10\n",
      "3135/3135 [==============================] - 4s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0013 - val_loss: 0.0000e+00 - val_accuracy: 1.7944e-04\n",
      "Epoch 5/10\n",
      "3135/3135 [==============================] - 4s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0013 - val_loss: 0.0000e+00 - val_accuracy: 1.7944e-04\n",
      "Epoch 6/10\n",
      "3135/3135 [==============================] - 3s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0013 - val_loss: 0.0000e+00 - val_accuracy: 1.7944e-04\n",
      "Epoch 7/10\n",
      "3135/3135 [==============================] - 4s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0013 - val_loss: 0.0000e+00 - val_accuracy: 1.7944e-04\n",
      "Epoch 8/10\n",
      "3135/3135 [==============================] - 4s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0013 - val_loss: 0.0000e+00 - val_accuracy: 1.7944e-04\n",
      "Epoch 9/10\n",
      "3135/3135 [==============================] - 3s 943us/step - loss: 0.0000e+00 - accuracy: 0.0013 - val_loss: 0.0000e+00 - val_accuracy: 1.7944e-04\n",
      "Epoch 10/10\n",
      "3135/3135 [==============================] - 3s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0013 - val_loss: 0.0000e+00 - val_accuracy: 1.7944e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f9c7152e460>"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "#### train the model with epochs ####\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "model.fit(X_train_enc, y_train_enc, epochs=epochs, batch_size=batch_size,validation_split=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.12\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "test, accuracy = model.evaluate(X_evaluation_enc, y_evaluation_enc, verbose=0)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991/1991 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "testy_pred = model.predict(X_evaluation_enc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.],\n       [1.],\n       [1.],\n       ...,\n       [1.],\n       [1.],\n       [1.]], dtype=float32)"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}