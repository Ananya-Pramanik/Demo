{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages imported...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# example of one hot encoding for a neural network\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# Scaling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print('Packages imported...')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "# load the train dataset\n",
    "def load_dataset(train, test, evaluation):\n",
    "\t# load the dataset as a pandas DataFrame\n",
    "\tprint(\"load the dataset as a pandas DataFrame\")\n",
    "\ttrain = pd.read_csv(train)\n",
    "\ttest = pd.read_csv(test)\n",
    "\tevaluation = pd.read_csv(evaluation)\n",
    "\n",
    "\ttrain = train.replace(np.nan, 'none').astype(str)\n",
    "\ttest = test.replace(np.nan, 'none').astype(str)\n",
    "\tevaluation = evaluation.replace(np.nan, 'none').astype(str)\n",
    "\n",
    "\tprint(train.info())\n",
    "\n",
    "    # select columns\n",
    "\tprint(\"select columns\")\n",
    "\ttrain_df = train[['consumed_part_name','pfmea_potential_effect_of_failure','pfmea_severity']]\n",
    "\tprint(train_df)\n",
    "\t# train_df['consumed_part_name'] = train_df['consumed_part_name'].fillna('0')\n",
    "\t# train_df['pfmea_potential_effect_of_failure'] = train_df['pfmea_potential_effect_of_failure'].fillna('0')\n",
    "\t# train_df['pfmea_severity'] = train_df['pfmea_severity'].fillna(\"0\")\n",
    "\ttest_df = test[['consumed_part_name','pfmea_potential_effect_of_failure','pfmea_severity']]\n",
    "\tprint(test_df)\n",
    "\t# test_df['consumed_part_name'] = test_df['consumed_part_name'].fillna('0')\n",
    "\t# test_df['pfmea_potential_effect_of_failure'] = test_df['pfmea_potential_effect_of_failure'].fillna('0')\n",
    "\t# test_df['pfmea_severity'] = test_df['pfmea_severity'].fillna(\"0\")\n",
    "\tevaluation_df = evaluation[['consumed_part_name','pfmea_potential_effect_of_failure','pfmea_severity']]\n",
    "\tprint(evaluation_df)\n",
    "\t# evaluation_df['consumed_part_name'] = evaluation_df['consumed_part_name'].fillna('0')\n",
    "\t# evaluation_df['pfmea_potential_effect_of_failure'] = evaluation_df['pfmea_potential_effect_of_failure'].fillna('0')\n",
    "\t# evaluation_df['pfmea_severity'] = evaluation_df['pfmea_severity'].fillna(\"0\")\n",
    "\n",
    "\n",
    "\t# retrieve numpy array\n",
    "\tprint(\"retrieve numpy array\")\n",
    "\t#Considering y variable holds numpy array\n",
    "\t# dataset_train = tf.convert_to_tensor(train_df, dtype=tf.int64)\n",
    "\t# dataset_test = tf.convert_to_tensor(test_df, dtype=tf.int64)\n",
    "\t# evaluation_test = tf.convert_to_tensor(evaluation_df, dtype=tf.int64)\n",
    "\tdataset_train = train_df\n",
    "\tdataset_test = test_df\n",
    "\tevaluation_test = evaluation_df\n",
    "\t# dataset_train = train_df.values\n",
    "\t# dataset_test = test_df.values\n",
    "\t# evaluation_test = evaluation_df.values\n",
    "\n",
    "\t# Define Features and Label\n",
    "\tfeature = ['consumed_part_name','pfmea_potential_effect_of_failure']\n",
    "\tlabel = ['pfmea_severity']\n",
    "\n",
    "\t# split into input (X) and output (y) variables\n",
    "\tprint(\"split into input (X) and output (y) variables\")\n",
    "\tX_train = dataset_train[feature].values\n",
    "\ty_train = dataset_train[label].values\n",
    "\n",
    "\tX_test = dataset_test[feature].values\n",
    "\ty_test = dataset_test[label].values\n",
    "\n",
    "\tX_evaluation = evaluation_test[feature].values\n",
    "\ty_evaluation = evaluation_test[label].values\n",
    "\n",
    "\n",
    "\t# # format all fields as string\n",
    "\t# print(\"format all fields as string\")\n",
    "\t# X_train = X_train.astype(str)\n",
    "\t# X_test = X_test.astype(str)\n",
    "\t# X_evaluation = X_evaluation.astype(str)\n",
    "\t# y_train = y_train.astype(str)\n",
    "\t# y_test = y_test.astype(str)\n",
    "\t# y_evaluation = y_evaluation.astype(str)\n",
    "\n",
    "\t# reshape target to be a 2d array\n",
    "\tprint(\"reshape target to be a 2d array\")\n",
    "\ty_train = y_train.reshape((len(y_train), 1))\n",
    "\ty_test = y_test.reshape((len(y_test), 1))\n",
    "\ty_evaluation = y_evaluation.reshape((len(y_evaluation), 1))\n",
    "\n",
    "\tprint(\"Done\")\n",
    "\n",
    "\n",
    "\treturn X_train, y_train, X_test, y_test, X_evaluation, y_evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "# prepare input train data\n",
    "def prepare_inputs(X_train, X_test, X_evaluation):\n",
    "\tprint(\"prepare input train data\")\n",
    "\tohe = OrdinalEncoder()\n",
    "\tohe.fit(X_train)\n",
    "\tX_train_enc = ohe.fit_transform(X_train)\n",
    "\tX_test_enc = ohe.fit_transform(X_test)\n",
    "\tX_evaluation_enc = ohe.fit_transform(X_evaluation)\n",
    "\tprint(\"Done\")\n",
    "\treturn X_train_enc, X_test_enc, X_evaluation_enc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "# prepare target\n",
    "def prepare_targets(y_train, y_test, y_evaluation):\n",
    "\tprint(\"prepare target\")\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(y_train)\n",
    "\ty_train_enc = le.transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\ty_evaluation_enc = le.transform(y_evaluation)\n",
    "\tprint(\"Done\")\n",
    "\treturn y_train_enc, y_test_enc, y_evaluation_enc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "train = 'training.csv'\n",
    "test = 'test.csv'\n",
    "evaluation = 'evaluation.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load the dataset as a pandas DataFrame\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9z/xcg1b2s55v36mhfj9jw2fwsh0000gn/T/ipykernel_29841/1475370861.py:5: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv(train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196782 entries, 0 to 196781\n",
      "Data columns (total 30 columns):\n",
      " #   Column                               Non-Null Count   Dtype \n",
      "---  ------                               --------------   ----- \n",
      " 0   plant                                196782 non-null  object\n",
      " 1   line_mrn                             196782 non-null  object\n",
      " 2   sub_process_station                  196782 non-null  object\n",
      " 3   task_number                          196782 non-null  object\n",
      " 4   consumed_part_number                 196782 non-null  object\n",
      " 5   task_list_description                196782 non-null  object\n",
      " 6   consumed_part_top_number             196782 non-null  object\n",
      " 7   consumed_part_name                   196782 non-null  object\n",
      " 8   consumed_part_state                  196782 non-null  object\n",
      " 9   consumed_part_description            196782 non-null  object\n",
      " 10  consumed_part_assembly_instructions  196782 non-null  object\n",
      " 11  consumed_part_top_name               196782 non-null  object\n",
      " 12  task_description                     196782 non-null  object\n",
      " 13  station_number                       196782 non-null  object\n",
      " 14  pfmea_number                         196782 non-null  object\n",
      " 15  pfmea_version                        196782 non-null  object\n",
      " 16  pfmea_local_ecn_number               196782 non-null  object\n",
      " 17  pfmea_local_ecn_effectivity          196782 non-null  object\n",
      " 18  pfmea_maap_failure_mode_group        196782 non-null  object\n",
      " 19  pfmea_maap_risk_level                196782 non-null  object\n",
      " 20  pfmea_potential_failure_mode         196782 non-null  object\n",
      " 21  pfmea_potential_effect_of_failure    196782 non-null  object\n",
      " 22  pfmea_potential_cause_of_failure     196782 non-null  object\n",
      " 23  pfmea_process_control_prevention     196782 non-null  object\n",
      " 24  pfmea_process_control_detection      196782 non-null  object\n",
      " 25  pfmea_severity                       196782 non-null  object\n",
      " 26  pfmea_occurrences                    196782 non-null  object\n",
      " 27  pfmea_detection                      196782 non-null  object\n",
      " 28  pfmea_rpn                            196782 non-null  object\n",
      " 29  uuid                                 196782 non-null  object\n",
      "dtypes: object(30)\n",
      "memory usage: 45.0+ MB\n",
      "None\n",
      "select columns\n",
      "       consumed_part_name           pfmea_potential_effect_of_failure  \\\n",
      "0                   STRAP  Inability to perform next task / operation   \n",
      "1                   STRAP  Inability to perform next task / operation   \n",
      "2               Converter                     Damaged / contamination   \n",
      "3               Converter                                 Safety risk   \n",
      "4               Converter                     Damaged / contamination   \n",
      "...                   ...                                         ...   \n",
      "196777             WASHER                                       Noise   \n",
      "196778           RETAINER                                       Noise   \n",
      "196779             WASHER                  Premature failure of parts   \n",
      "196780             WASHER                                       Noise   \n",
      "196781           RETAINER                  Premature failure of parts   \n",
      "\n",
      "       pfmea_severity  \n",
      "0                   6  \n",
      "1                   6  \n",
      "2                   7  \n",
      "3                   9  \n",
      "4                   7  \n",
      "...               ...  \n",
      "196777              5  \n",
      "196778              5  \n",
      "196779              5  \n",
      "196780              5  \n",
      "196781              5  \n",
      "\n",
      "[196782 rows x 3 columns]\n",
      "      consumed_part_name           pfmea_potential_effect_of_failure  \\\n",
      "0           Exhaust Pipe                  Premature failure of parts   \n",
      "1                 Gasket                  Premature failure of parts   \n",
      "2                 WASHER                                       Noise   \n",
      "3                Bracket                                   Vibration   \n",
      "4                Support  Inability to perform next task / operation   \n",
      "...                  ...                                         ...   \n",
      "31840      Control Valve                                        none   \n",
      "31841      Control Valve                                        none   \n",
      "31842           RETAINER                                       Noise   \n",
      "31843           RETAINER                                       Noise   \n",
      "31844          Cap Screw                  Premature failure of parts   \n",
      "\n",
      "      pfmea_severity  \n",
      "0               none  \n",
      "1               none  \n",
      "2               none  \n",
      "3               none  \n",
      "4               none  \n",
      "...              ...  \n",
      "31840           none  \n",
      "31841           none  \n",
      "31842           none  \n",
      "31843           none  \n",
      "31844           none  \n",
      "\n",
      "[31845 rows x 3 columns]\n",
      "      consumed_part_name                  pfmea_potential_effect_of_failure  \\\n",
      "0                SUPPORT                                               none   \n",
      "1                  Clamp                         Premature failure of parts   \n",
      "2                 Gasket  Loss of pressure fluid / leakage in fluid syst...   \n",
      "3                 Gasket                         Premature failure of parts   \n",
      "4                  Clamp  Loss of pressure fluid / leakage in fluid syst...   \n",
      "...                  ...                                                ...   \n",
      "63684            CONDUIT                         Premature failure of parts   \n",
      "63685      Control Valve                                               none   \n",
      "63686      Control Valve                                               none   \n",
      "63687           RETAINER                         Premature failure of parts   \n",
      "63688          Cap Screw                                              Noise   \n",
      "\n",
      "      pfmea_severity  \n",
      "0               none  \n",
      "1                7.0  \n",
      "2                7.0  \n",
      "3                7.0  \n",
      "4                7.0  \n",
      "...              ...  \n",
      "63684            4.0  \n",
      "63685           none  \n",
      "63686           none  \n",
      "63687            5.0  \n",
      "63688            5.0  \n",
      "\n",
      "[63689 rows x 3 columns]\n",
      "retrieve numpy array\n",
      "split into input (X) and output (y) variables\n",
      "reshape target to be a 2d array\n",
      "Done\n",
      "prepare input train data\n",
      "Done\n",
      "prepare target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ananya_pramanik/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ananya_pramanik/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'none'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_encode.py:182\u001B[0m, in \u001B[0;36m_encode\u001B[0;34m(values, uniques, check_unknown)\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_map_to_integer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muniques\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_encode.py:126\u001B[0m, in \u001B[0;36m_map_to_integer\u001B[0;34m(values, uniques)\u001B[0m\n\u001B[1;32m    125\u001B[0m table \u001B[38;5;241m=\u001B[39m _nandict({val: i \u001B[38;5;28;01mfor\u001B[39;00m i, val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(uniques)})\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([table[v] \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m values])\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_encode.py:126\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    125\u001B[0m table \u001B[38;5;241m=\u001B[39m _nandict({val: i \u001B[38;5;28;01mfor\u001B[39;00m i, val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(uniques)})\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([\u001B[43mtable\u001B[49m\u001B[43m[\u001B[49m\u001B[43mv\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m values])\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_encode.py:120\u001B[0m, in \u001B[0;36m_nandict.__missing__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnan_value\n\u001B[0;32m--> 120\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'none'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [264]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m X_train_enc, X_test_enc,X_evaluation_enc \u001B[38;5;241m=\u001B[39m prepare_inputs(X_train, X_test, X_evaluation)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# prepare output data\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m y_train_enc, y_test_enc, y_evaluation_enc \u001B[38;5;241m=\u001B[39m \u001B[43mprepare_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_evaluation\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [262]\u001B[0m, in \u001B[0;36mprepare_targets\u001B[0;34m(y_train, y_test, y_evaluation)\u001B[0m\n\u001B[1;32m      5\u001B[0m le\u001B[38;5;241m.\u001B[39mfit(y_train)\n\u001B[1;32m      6\u001B[0m y_train_enc \u001B[38;5;241m=\u001B[39m le\u001B[38;5;241m.\u001B[39mtransform(y_train)\n\u001B[0;32m----> 7\u001B[0m y_test_enc \u001B[38;5;241m=\u001B[39m \u001B[43mle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m y_evaluation_enc \u001B[38;5;241m=\u001B[39m le\u001B[38;5;241m.\u001B[39mtransform(y_evaluation)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:138\u001B[0m, in \u001B[0;36mLabelEncoder.transform\u001B[0;34m(self, y)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _num_samples(y) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([])\n\u001B[0;32m--> 138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_encode\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muniques\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclasses_\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_encode.py:184\u001B[0m, in \u001B[0;36m_encode\u001B[0;34m(values, uniques, check_unknown)\u001B[0m\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _map_to_integer(values, uniques)\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 184\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my contains previously unseen labels: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check_unknown:\n",
      "\u001B[0;31mValueError\u001B[0m: y contains previously unseen labels: 'none'"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "X_train, y_train, X_test, y_test, X_evaluation, y_evaluation = load_dataset(train, test, evaluation)\n",
    "\n",
    "# prepare input data\n",
    "X_train_enc, X_test_enc,X_evaluation_enc = prepare_inputs(X_train, X_test, X_evaluation)\n",
    "\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc, y_evaluation_enc = prepare_targets(y_train, y_test, y_evaluation)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196782, 2) (31845, 2) (63689, 2)\n",
      "(196782, 1) (31845, 1) (63689, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, X_evaluation.shape)\n",
    "print(y_train.shape, y_test.shape, y_evaluation.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare input train data\n",
      "Done\n",
      "(196782, 2) (31845, 2) (63689, 2)\n",
      "[[633.   7.]\n",
      " [633.   7.]\n",
      " [167.   2.]\n",
      " ...\n",
      " [780.  21.]\n",
      " [780.  18.]\n",
      " [550.  21.]]\n"
     ]
    }
   ],
   "source": [
    "# prepare input data\n",
    "X_train_enc, X_test_enc,X_evaluation_enc = prepare_inputs(X_train, X_test, X_evaluation)\n",
    "print(X_train_enc.shape, X_test_enc.shape, X_evaluation_enc.shape)\n",
    "print(X_train_enc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ananya_pramanik/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/ananya_pramanik/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'none'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_encode.py:182\u001B[0m, in \u001B[0;36m_encode\u001B[0;34m(values, uniques, check_unknown)\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 182\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_map_to_integer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muniques\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_encode.py:126\u001B[0m, in \u001B[0;36m_map_to_integer\u001B[0;34m(values, uniques)\u001B[0m\n\u001B[1;32m    125\u001B[0m table \u001B[38;5;241m=\u001B[39m _nandict({val: i \u001B[38;5;28;01mfor\u001B[39;00m i, val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(uniques)})\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([table[v] \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m values])\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_encode.py:126\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    125\u001B[0m table \u001B[38;5;241m=\u001B[39m _nandict({val: i \u001B[38;5;28;01mfor\u001B[39;00m i, val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(uniques)})\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([\u001B[43mtable\u001B[49m\u001B[43m[\u001B[49m\u001B[43mv\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m values])\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_encode.py:120\u001B[0m, in \u001B[0;36m_nandict.__missing__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnan_value\n\u001B[0;32m--> 120\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'none'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [257]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# prepare output data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m y_train_enc, y_test_enc, y_evaluation_enc \u001B[38;5;241m=\u001B[39m \u001B[43mprepare_targets\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_evaluation\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(y_train_enc\u001B[38;5;241m.\u001B[39mshape, y_test_enc\u001B[38;5;241m.\u001B[39mshape, y_evaluation_enc\u001B[38;5;241m.\u001B[39mshape)\n",
      "Input \u001B[0;32mIn [252]\u001B[0m, in \u001B[0;36mprepare_targets\u001B[0;34m(y_train, y_test, y_evaluation)\u001B[0m\n\u001B[1;32m      5\u001B[0m le\u001B[38;5;241m.\u001B[39mfit(y_train)\n\u001B[1;32m      6\u001B[0m y_train_enc \u001B[38;5;241m=\u001B[39m le\u001B[38;5;241m.\u001B[39mtransform(y_train)\n\u001B[0;32m----> 7\u001B[0m y_test_enc \u001B[38;5;241m=\u001B[39m \u001B[43mle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m y_evaluation_enc \u001B[38;5;241m=\u001B[39m le\u001B[38;5;241m.\u001B[39mtransform(y_evaluation)\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:138\u001B[0m, in \u001B[0;36mLabelEncoder.transform\u001B[0;34m(self, y)\u001B[0m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _num_samples(y) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([])\n\u001B[0;32m--> 138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_encode\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muniques\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclasses_\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/_encode.py:184\u001B[0m, in \u001B[0;36m_encode\u001B[0;34m(values, uniques, check_unknown)\u001B[0m\n\u001B[1;32m    182\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _map_to_integer(values, uniques)\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 184\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my contains previously unseen labels: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check_unknown:\n",
      "\u001B[0;31mValueError\u001B[0m: y contains previously unseen labels: 'none'"
     ]
    }
   ],
   "source": [
    "# prepare output data\n",
    "y_train_enc, y_test_enc, y_evaluation_enc = prepare_targets(y_train, y_test, y_evaluation)\n",
    "print(y_train_enc.shape, y_test_enc.shape, y_evaluation_enc.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (196782, 2)\n",
      "y_train (196782, 1)\n",
      "X_test (31845, 2)\n",
      "y_test (31845, 1)\n",
      "X_evaluation (63689, 2)\n",
      "y_evaluation (63689, 1)\n",
      "X_train_enc (196782, 2)\n",
      "X_test_enc (31845, 2)\n",
      "X_evaluation_enc (63689, 2)\n",
      "y_train_enc (222911,)\n",
      "y_test_enc (31845,)\n",
      "y_evaluation_enc (63689,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train',X_train.shape)\n",
    "print('y_train',y_train.shape)\n",
    "print('X_test',X_test.shape)\n",
    "print('y_test',y_test.shape)\n",
    "print('X_evaluation',X_evaluation.shape)\n",
    "print('y_evaluation',y_evaluation.shape)\n",
    "\n",
    "print('X_train_enc',X_train_enc.shape)\n",
    "print('X_test_enc',X_test_enc.shape)\n",
    "print('X_evaluation_enc',X_evaluation_enc.shape)\n",
    "\n",
    "print('y_train_enc',y_train_enc.shape)\n",
    "print('y_test_enc',y_test_enc.shape)\n",
    "print('y_evaluation_enc',y_evaluation_enc.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [196782, 222911]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [249]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m gbt \u001B[38;5;241m=\u001B[39m GradientBoostingClassifier(n_estimators \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,subsample\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m,max_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m,random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# fitting the model\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[43mgbt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_enc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train_enc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# predicting values\u001B[39;00m\n\u001B[1;32m      8\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m gbt\u001B[38;5;241m.\u001B[39mpredict(X_evaluation_enc)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:486\u001B[0m, in \u001B[0;36mBaseGradientBoosting.fit\u001B[0;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[1;32m    480\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_clear_state()\n\u001B[1;32m    482\u001B[0m \u001B[38;5;66;03m# Check input\u001B[39;00m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;66;03m# Since check_array converts both X and y to the same dtype, but the\u001B[39;00m\n\u001B[1;32m    484\u001B[0m \u001B[38;5;66;03m# trees use different types for X and y, checking them separately.\u001B[39;00m\n\u001B[0;32m--> 486\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcoo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m    488\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    490\u001B[0m sample_weight_is_none \u001B[38;5;241m=\u001B[39m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    492\u001B[0m sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:581\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    579\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    580\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 581\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    584\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:981\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m    964\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m    965\u001B[0m     X,\n\u001B[1;32m    966\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    976\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mestimator,\n\u001B[1;32m    977\u001B[0m )\n\u001B[1;32m    979\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric)\n\u001B[0;32m--> 981\u001B[0m \u001B[43mcheck_consistent_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    983\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X, y\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:332\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    330\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 332\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    333\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    334\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[1;32m    335\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [196782, 222911]"
     ]
    }
   ],
   "source": [
    "# instantiate the classifier\n",
    "gbt = GradientBoostingClassifier(n_estimators = 1, max_depth=1,subsample=0.8,max_features=0.2,random_state=42)\n",
    "\n",
    "# fitting the model\n",
    "gbt.fit(X_train_enc, y_train_enc)\n",
    "\n",
    "# predicting values\n",
    "y_pred = gbt.predict(X_evaluation_enc)\n",
    "print(\"The test accuracy score of Gradient Boosting Classifier is \", accuracy_score(y_test_enc, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}